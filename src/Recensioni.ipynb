{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christian\\universita\\magistrale\\ianno\\dataanalytics\\progetto\\dataanalyticsproject\\src\\venv_da\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import word_tokenize\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "\n",
    "import string\n",
    "from nltk import wordpunct_tokenize\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "#progress bar\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "# instantiate\n",
    "tqdm.pandas(tqdm_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviewsChunk = pd.read_json('../data/reviews.json', lines=True, chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunk_list = []  # append each chunk df here \n",
    "\n",
    "# Each chunk is in df format\n",
    "for chunk in dataReviewsChunk:\n",
    "\n",
    "    chunk_list.append(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviews = pd.concat(chunk_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews not filtered: 1988854\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of reviews not filtered:\", len(dataReviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_int_value(int_value):\n",
    "    return int_value[\"$numberInt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviews[\"rating\"]=dataReviews[\"rating\"].apply(convert_int_value).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviews[\"helpful\"]=dataReviews[\"helpful\"].apply(convert_int_value).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviews = dataReviews[dataReviews.helpful != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviews = dataReviews[dataReviews.verified == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dataReviews[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced reviews distribution [5-1] stars: [215539  65647  44671  31161  20653]\n"
     ]
    }
   ],
   "source": [
    "print(\"Reduced reviews distribution [5-1] stars:\", counts.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([5, 4, 1, 3, 2], dtype='int64')\n",
      "[215539  65647  44671  31161  20653]\n"
     ]
    }
   ],
   "source": [
    "x = counts._index\n",
    "print(x)\n",
    "y = counts.values\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(18,6))\n",
    "sns.barplot(x=counts._index, y=counts.values)\n",
    "plt.title(\"Rating distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of review with score=1: 11.828019625547103%\n",
      "Proportion of review with score=2: 5.468516248268996%\n",
      "Proportion of review with score=3: 8.2508320734184%\n",
      "Proportion of review with score=4: 17.3820600469721%\n",
      "Proportion of review with score=5: 57.07057200579341%\n"
     ]
    }
   ],
   "source": [
    "print(\"Proportion of review with score=1: {}%\".format(len(dataReviews[dataReviews.rating == 1]) / len(dataReviews)*100))\n",
    "print(\"Proportion of review with score=2: {}%\".format(len(dataReviews[dataReviews.rating == 2]) / len(dataReviews)*100))\n",
    "print(\"Proportion of review with score=3: {}%\".format(len(dataReviews[dataReviews.rating == 3]) / len(dataReviews)*100))\n",
    "print(\"Proportion of review with score=4: {}%\".format(len(dataReviews[dataReviews.rating == 4]) / len(dataReviews)*100))\n",
    "print(\"Proportion of review with score=5: {}%\".format(len(dataReviews[dataReviews.rating == 5]) / len(dataReviews)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviews_POS = pd.DataFrame(dataReviews[dataReviews.rating > 3].sample(500))\n",
    "dataReviews_POS['target'] = 'POS'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviews_NEG = pd.DataFrame(dataReviews[dataReviews.rating < 3].sample(500))\n",
    "dataReviews_NEG['target'] = 'NEG'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviews_NEUT = pd.DataFrame(dataReviews[dataReviews.rating == 3].sample(500))\n",
    "dataReviews_NEUT['target'] = 'NEU'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export csv to do sentix in R\n",
    "dataReviews_POS.to_csv('../data/dataReviews_POS.csv')\n",
    "dataReviews_NEG.to_csv('../data/dataReviews_NEG.csv')\n",
    "dataReviews_NEUT.to_csv('../data/dataReviews_NEUT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"italian\")\n",
    "def stemming_token(sentence,stemmer):\n",
    "    stem = []\n",
    "    for elem in sentence:\n",
    "        stem.append(stemmer.stem(elem))\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>synset_ID</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>polarity</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abile</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lemma POS  synset_ID  score_1  score_2  polarity  intensity\n",
       "0  abile   a       1740    0.125      0.0       1.0      0.125"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentix = pd.read_csv(\"../data/sentix.csv\", sep=\"\\t\", header=None)\n",
    "sentix.columns=[\"lemma\", \"POS\", \"synset_ID\", \"score_1\", \"score_2\", \"polarity\", \"intensity\"] \n",
    "sentix.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>synset_ID</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>polarity</th>\n",
       "      <th>intensity</th>\n",
       "      <th>stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abile</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>abil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intelligente</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>intelligent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valente</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>valent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capace</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>capac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>incapace</td>\n",
       "      <td>a</td>\n",
       "      <td>2098</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>incapac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lemma POS  synset_ID  score_1  score_2  polarity  intensity  \\\n",
       "0         abile   a       1740    0.125     0.00       1.0      0.125   \n",
       "1  intelligente   a       1740    0.125     0.00       1.0      0.125   \n",
       "2       valente   a       1740    0.125     0.00       1.0      0.125   \n",
       "3        capace   a       1740    0.125     0.00       1.0      0.125   \n",
       "4      incapace   a       2098    0.000     0.75      -1.0      0.750   \n",
       "\n",
       "      stemming  \n",
       "0         abil  \n",
       "1  intelligent  \n",
       "2       valent  \n",
       "3        capac  \n",
       "4      incapac  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentix[\"lemma\"] = sentix[\"lemma\"].astype(str)\n",
    "sentix[\"stemming\"] = sentix[\"lemma\"].apply(stemmer.stem)\n",
    "sentix.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>synset_ID</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>polarity</th>\n",
       "      <th>intensity</th>\n",
       "      <th>stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abile</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>abil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lemma POS  synset_ID  score_1  score_2  polarity  intensity stemming\n",
       "0  abile   a       1740    0.125      0.0       5.0      0.125     abil"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentix[\"polarity\"] = sentix[\"polarity\"]*5\n",
    "sentix.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentix for lexicon based sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentix_agg = sentix.loc[sentix[\"POS\"]==\"a\"]\n",
    "\n",
    "# add extra words\n",
    "sentix_agg = sentix_agg.append({'stemming': stemmer.stem('reso'), 'polarity': -5, 'intensity': 1, 'synset_ID': '00048739'}, ignore_index = True)\n",
    "sentix_agg = sentix_agg.append({'stemming': stemmer.stem('restituito'), 'polarity': -5, 'intensity': 1, 'synset_ID': '00048739'}, ignore_index = True)\n",
    "sentix_agg = sentix_agg.append({'stemming': 'bel', 'polarity': 5, 'intensity': 1, 'synset_ID': '00217728'}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentix = sentix.append({'stemming': stemmer.stem('reso'), 'polarity': -5, 'intensity': 1, 'synset_ID': '00048739'}, ignore_index = True)\n",
    "sentix = sentix.append({'stemming': stemmer.stem('restituito'), 'polarity': -5, 'intensity': 1, 'synset_ID': '00048739'}, ignore_index = True)\n",
    "sentix = sentix.append({'stemming': 'bel', 'polarity': 5, 'intensity': 1, 'synset_ID': '00217728'}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lemma        NaN\n",
       "POS          NaN\n",
       "synset_ID    NaN\n",
       "score_1      NaN\n",
       "score_2      NaN\n",
       "polarity       5\n",
       "intensity    NaN\n",
       "stemming     bel\n",
       "Name: 3373, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentix_agg.iloc[len(sentix_agg)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviews_POS[\"token\"] = dataReviews_POS[\"body\"].apply(word_tokenize)\n",
    "dataReviews_POS[\"stemming\"] = [stemming_token(row[\"token\"], stemmer) for _, row in dataReviews_POS.iterrows()]\n",
    "dataReviews_NEG[\"token\"] = dataReviews_NEG[\"body\"].apply(word_tokenize)\n",
    "dataReviews_NEG[\"stemming\"] = [stemming_token(row[\"token\"], stemmer) for _, row in dataReviews_NEG.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviews_POS.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviews_NEG.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics \n",
    "\n",
    "def lexicon_based_score(sentence,df_sentix):\n",
    "    sum_pol = 0\n",
    "    count=0\n",
    "    #print(sentence)\n",
    "    context = None\n",
    "    for elem in sentence:\n",
    "        #polarity = df_sentix[df_sentix.stemming  == elem]['polarity']\n",
    "        values = df_sentix[df_sentix.stemming  == elem][['polarity','intensity','synset_ID']]\n",
    "        if not(values.empty):\n",
    "            count += 1\n",
    "            #print(elem)\n",
    "            #print(polarity)\n",
    "            #print(sum_pol)\n",
    "            #if len(polarity >1):\n",
    "                #print(type(polarity.iloc[0]))\n",
    "                #print(\"polarity\",polarity.value_counts())\n",
    "            #sum_pol += polarity.value_counts().index[0]#statistics.mean(polarity)\n",
    "            synset_values = values[values.synset_ID == context]           \n",
    "            if synset_values.empty:\n",
    "                synset_values = values.iloc[0]\n",
    "                context = synset_values['synset_ID']\n",
    "            else:\n",
    "                synset_values =  synset_values.iloc[0]\n",
    "            sum_pol += synset_values['polarity']*synset_values['intensity']\n",
    "            \n",
    "            #print(polarity)\n",
    "            #print(statistics.mean(polarity))\n",
    "            #else:\n",
    "            #    sum_pol += polarity\n",
    "    #print(sum_pol)\n",
    "    #print(\"_________________________________________________________\")\n",
    "    if count != 0:\n",
    "        return sum_pol/count\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.875"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity = sentix[sentix.stemming  == stemmer.stem('subito')][['polarity','intensity','synset_ID']]\n",
    "polarity.iloc[0]['polarity']*polarity.iloc[0]['intensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentix on positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████▊                                        | 45/250 [00:09<00:43,  4.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-8d69860ac398>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataReviews_POS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pol\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataReviews_POS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stemming\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlexicon_based_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentix_agg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\christian\\universita\\magistrale\\ianno\\dataanalytics\\progetto\\dataanalyticsproject\\src\\venv_da\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    765\u001b[0m                 \u001b[1;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m                 \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christian\\universita\\magistrale\\ianno\\dataanalytics\\progetto\\dataanalyticsproject\\src\\venv_da\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3848\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christian\\universita\\magistrale\\ianno\\dataanalytics\\progetto\\dataanalyticsproject\\src\\venv_da\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    760\u001b[0m                     \u001b[1;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m                 \u001b[1;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-142-8d69860ac398>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataReviews_POS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pol\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataReviews_POS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stemming\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlexicon_based_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentix_agg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-134-e0885f5554ac>\u001b[0m in \u001b[0;36mlexicon_based_score\u001b[1;34m(sentence, df_sentix)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m#polarity = df_sentix[df_sentix.stemming  == elem]['polarity']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_sentix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_sentix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstemming\u001b[0m  \u001b[1;33m==\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'polarity'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'intensity'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'synset_ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christian\\universita\\magistrale\\ianno\\dataanalytics\\progetto\\dataanalyticsproject\\src\\venv_da\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2810\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2812\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2814\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christian\\universita\\magistrale\\ianno\\dataanalytics\\progetto\\dataanalyticsproject\\src\\venv_da\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   3407\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3408\u001b[0m         \"\"\"\n\u001b[1;32m-> 3409\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3410\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christian\\universita\\magistrale\\ianno\\dataanalytics\\progetto\\dataanalyticsproject\\src\\venv_da\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3392\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3394\u001b[1;33m         new_data = self._data.take(\n\u001b[0m\u001b[0;32m   3395\u001b[0m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3396\u001b[0m         )\n",
      "\u001b[1;32mc:\\users\\christian\\universita\\magistrale\\ianno\\dataanalytics\\progetto\\dataanalyticsproject\\src\\venv_da\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1393\u001b[1;33m         return self.reindex_indexer(\n\u001b[0m\u001b[0;32m   1394\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1395\u001b[0m         )\n",
      "\u001b[1;32mc:\\users\\christian\\universita\\magistrale\\ianno\\dataanalytics\\progetto\\dataanalyticsproject\\src\\venv_da\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m             \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m             new_blocks = [\n",
      "\u001b[1;32mc:\\users\\christian\\universita\\magistrale\\ianno\\dataanalytics\\progetto\\dataanalyticsproject\\src\\venv_da\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mblklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m             blknos = algos.take_1d(\n\u001b[0m\u001b[0;32m   1315\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m             )\n",
      "\u001b[1;32mc:\\users\\christian\\universita\\magistrale\\ianno\\dataanalytics\\progetto\\dataanalyticsproject\\src\\venv_da\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m   1660\u001b[0m         \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m     )\n\u001b[1;32m-> 1662\u001b[1;33m     \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataReviews_POS[\"pol\"] = dataReviews_POS[\"stemming\"].progress_apply(lambda x: lexicon_based_score(x,sentix_agg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 250/250 [01:04<00:00,  3.90it/s]\n"
     ]
    }
   ],
   "source": [
    "dataReviews_NEG[\"pol\"] = dataReviews_NEG[\"stemming\"].progress_apply(lambda x: lexicon_based_score(x,sentix_agg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% accuracy POS:  91.2\n"
     ]
    }
   ],
   "source": [
    "print(\"% accuracy POS: \", len(dataReviews_POS.loc[dataReviews_POS.pol > 0])/len(dataReviews_POS)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% accuracy NEG:  41.6\n"
     ]
    }
   ],
   "source": [
    "print(\"% accuracy NEG: \", len(dataReviews_NEG.loc[dataReviews_NEG.pol < 0])/len(dataReviews_NEG)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pessimo acquisto..Non lo consiglio Pensavo fosse strutturato in maniera più semplice come lo sono le sue ricette che seguo sul web. Delusiione'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataReviews_NEG[dataReviews_NEG.pol > 0]['body'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pessim'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('pessim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prodotti nel tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviews[\"product\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prod = \"B00DDPI5NS\"\n",
    "#prod = \"B07DMJPV31\"\n",
    "df_product = dataReviews[dataReviews[\"product\"]  == prod]\n",
    "df_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#delete day\n",
    "df_product=df_product.assign(\n",
    "    Period=df_product.date.dt.to_period('M')\n",
    ")\n",
    "df_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product['token']=df_product['body'].progress_apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data[\"stemming\"]=[stemming_token(row[\"token\"], stemmer) for _, row in sub_data.iterrows()]\n",
    "df_product[\"stemming\"] = [stemming_token(df_product[\"token\"], stemmer) for _, row in df_product.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product['lexicon_score_sentix']= df_product[\"stemming\"].progress_apply(lambda x: lexicon_based_score(x,sentix_agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataReviews[\"product\"]\n",
    "df_month = df_product[['Period','rating']].groupby(['Period']).mean()\n",
    "df_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month.plot(style='.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product [df_product[\"Period\"]  == \"2019-03\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# considero periodi di 6 mesi\n",
    "def manage_date(date):\n",
    "    date= str(date)\n",
    "    datee = datetime.datetime.strptime(str(date), \"%Y-%m\")\n",
    "    six=1\n",
    "    if (datee.month > 6):\n",
    "        six=2\n",
    "    return str(datee.year)+\"-\"+str(six)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manage_date(df_product[\"Period\"].iloc[0])\n",
    "df_product[\"new_period\"] = df_product[\"Period\"].apply(manage_date)\n",
    "df_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_product_df = df_product[['new_period','rating']].groupby(['new_period']).mean()\n",
    "final_product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_product_df.plot(style='.-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulizia Testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReviews['token']=dataReviews['body'].progress_apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_list(l):\n",
    "    return  [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_common_tokens(tokens, title, n=20):\n",
    "    sentences = (list(itertools.chain(tokens)))\n",
    "    flat_sentences = flat_list(sentences)\n",
    "    counts = Counter(flat_sentences)\n",
    "    #print(counts.most_common(30))\n",
    "    common_words = [word[0] for word in counts.most_common(n)]\n",
    "    common_counts = [word[1] for word in counts.most_common(n)]\n",
    "    fig = plt.figure(figsize=(18,6))\n",
    "    sns.barplot(x=common_words, y=common_counts)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_common_tokens(sub_data['stemming'],'Most Common Tokens used in Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_Cloud(sentences):\n",
    "    flat_sentences = flat_list(sentences)\n",
    "    unique_string=(\" \").join(flat_sentences)\n",
    "\n",
    "    wordcloud = WordCloud(background_color=\"white\").generate(unique_string)\n",
    "    plt.figure(figsize = (10, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=nltk.corpus.stopwords.words('italian')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data[\"cleaned\"] = sub_data[\"stemming\"].apply(lambda sentence : [word for word in sentence if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = string.punctuation\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data[\"cleaned\"] = sub_data[\"cleaned\"].apply(lambda sentence : [word for word in sentence if word not in punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_numbers = r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data[\"cleaned\"] = sub_data[\"cleaned\"].apply(lambda sentence : [re.sub(regex_numbers,\"\",word) for word in sentence if re.sub(regex_numbers,\"\",word) != \"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminazione token di lunghezza 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data[\"cleaned\"] = sub_data[\"cleaned\"].apply(lambda sentence : [word for word in sentence if len(word)> 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_common_tokens(sub_data['cleaned'],'Most Common Tokens used in Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_Cloud(sub_data[\"cleaned\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = (list(itertools.chain(sub_data[\"cleaned\"])))\n",
    "flat_sentences = flat_list(sentences)\n",
    "counts = Counter(flat_sentences)\n",
    "counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install aspect-based-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aspect_based_sentiment_analysis as absa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = absa.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"La EA non sa proprio cosa sia un gioco di calcio,la difesa questo anno è ancora peggio degli altri anni,terzini che non marcano ne fanno la fase offensiva,centrali che corrono verso le fasce lasciando libero il campo per i cross,difesa davvero scandalosa anche peggio del 18 e non credevo fosse possibile,per non parlare poi del fut champions,uno dei pochi giochi che dopo averci giocato sei più arrabbiato che rilassato,giocatori con 88 di velocità che si fanno riprendere a campo aperto e giocatori con 92 di velocità che non li ripigli  nemmeno partendo prima te,tiri da fuori area tutti in porta o tutti fuori a partita ,nessuna via di mezzo,palle sui pali che sembrano radiocomandate,giocatori scarsi che sembrano fenomeni,rimpalli irreali,fisica del pallone fantascientifica .... Addio fifa,pes non mi piace ma almeno ho provato che cerca di simulare realmente una partita non ti spaccia un ping ping per un gioco di calcio.\"\n",
    "        \"Regalato a mio figlio, commento nel titolo, ci gioca in modo continuativo ormai da giorni e ne sembra entusiasta. Ho richiesto un commento da poter trascrivere e la risposta è stata ci sta bellazi che pare essere un complimentone da parte di un adolescente.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
